# OpenAudioLab
This page highlights audio-related works from Audio Group at Machine Creativity Lab, HKUST, led by [Wei XUE](www.weixue.com).

## Source Codes

[CoMoSpeech](https://github.com/zhenye234/CoMoSpeech)
* First one-step speech and singing voice synthesis via diffusion sampling, based on the consistency model.
* 150 times faster than real-time on a single NVIDIA A100 GPU, making diffusion-based speech synthesis truly practical.


[CoMoSVC](https://github.com/Grace9994/CoMoSVC)
* Singing voice conversion with one-step consistency model based sampling
* Much faster and better audio quality than so-vits-svc

## Openings

We are hiring PhD, Research Assistant, and Postdoc globally on generative audio research. Remote collaborations are welcome. Please contact weixue@ust.hk if you are interested.